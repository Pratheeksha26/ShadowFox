# ShadowFox

## Task 1
Develop an autocorrect keyboard system that anticipates the next word in a sentence by leveraging the contextual information provided by preceding words. This task involves the implementation of ngrams or recurrent neural networks to enhance predictive capabilities. The goal is to create an intuitive keyboard that improves user experience by accurately anticipating and suggesting the next word, thereby facilitating efficient and errorfree text input.
DEVELOP AN AUTOCORRECT KEYBOARD SYSTEM THAT IDENTIFIES MISSPELLED WORDS IN A TEXT INPUT AND PROVIDES AUTOCORRECTION SUGGESTIONS.

## Task 2
Your task is to develop an ML model for car selling price prediction and analysis. The deployed system will provide users with an approximate selling price for their cars based on several features, including fuel type, years of service, showroom price, number of previous owners, kilometers driven, whether the seller is a dealer or an individual, and transmission type (manual/automatic).
Dataset Link:
https://drive.google.com/file/d/1yFuNVPXM5CH6g0TthYKcTGrZCCJo6n8Z/view?us p=drive_link

## Task 3
Problem Statement: Embark on an AI-driven journey in the realm of natural language processing (NLP) and machine learning (ML) by deploying a Language Model (LM) of your choice. In this project, you are tasked with delving into the intricacies of LM technology, where the selection of the LM is entirely at your discretion. The comprehensive process involves not only implementing the chosen LM but also conducting an in depth analysis of its performance and capabilities.

Guidelines:

1.LM Selection: Choose an LM that aligns with your interests, whether it be cutting-edge models like GPT3, BERT, or even a specialized domain-specific LM. The selection should be driven by your curiosity and the specific context in which the LM will be applied.

2.Implementation in a Jupyter Notebook: Create a Jupyter notebook from scratch to implement and showcase the chosen LM. Provide a step-by-step demonstration of the implementation process, highlighting key features, parameters, and any unique aspects of the selected LM.

3.Exploration and Analysis: Conduct a thorough exploration of the LM's capabilities within the Jupyter notebook. Analyze its performance on sample text inputs, showcase its ability to understand context, and evaluate its language generation capabilities. This phase may involve experimenting with different input scenarios and documenting the LM's responses.

4.Research Questions and Objectives: Based on your exploration, define research questions that delve into the strengths and limitations of the chosen LM. Consider aspects such as contextual understanding, creativity in generating text, and adaptability to diverse domains. Tailor your research questions to extract meaningful insights from the LM's behavior.

5.Visualization of Results: Utilize visualization techniques to present the results of your LM analysis. This could involve graphical representations of the LM's responses, comparisons with baseline models, or even visualizing the attention mechanisms within the LM architecture. Visualization aids in conveying complex information in an accessible manner.

6.Project Alignment and Evaluation: Align your project with the overarching goals of advancing understanding in the field of NLP and ML. Ensure that your work aligns with best practices, ethical considerations, and the evolving landscape of LM technology. Regularly refer to the project description and grading rubric to meet the specified requirements and expectations.

7. Conclusion and Insights: Summarize your findings, draw insightful conclusions from the LM analysis, and discuss potential applications or areas for improvement. Reflect on the broader implications of your work within the context of the rapidly evolving field of AI and LM technologies.

Resources: https://roadmap.sh/ai-data-scientist
